{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SAKI SS 2021 Homework {1}</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing and feature extraction.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "Auftragskonto\n",
      "Buchungstag\n",
      "Valutadatum\n",
      "Buchungstext\n",
      "Verwendungszweck\n",
      "Beguenstigter/Zahlungspflichtiger\n",
      "Kontonummer\n",
      "BLZ\n",
      "Betrag\n",
      "Waehrung\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_path = os.path.join(\"..\", \"data\", \"SAKI Exercise 1 - Transaction Classification - Data Set.csv\")\n",
    "df = pd.read_csv(input_path, ';')\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample consist of 10 feature and one label (without first column which is simply a number of row in dataset). \n",
    "<p>Buchungstag/Valutadatum are irrelavent for classification because any transaction can be at any date. Someone can say that the entries of \"living\" class has rental fee and these payments typically has a date at the end of month (25-31th) but as we see from the table below, there is direct relationship between \"Buchungstext\" and \"Buchungstag\": \"Meite\" has date between 25th-31st and the date for \"Lastschrift\" or \"Euro-Überweisung\" is earlier as 25th. So that even for this case, knowledge of the exact date of the transfer will not improve the classifier.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Buchungstag                       Buchungstext   label\n",
      "1    27.07.2016                              Miete  living\n",
      "11   28.06.2016                              Miete  living\n",
      "22   27.05.2016                              Miete  living\n",
      "29   27.04.2016                              Miete  living\n",
      "35   29.03.2016                              Miete  living\n",
      "41   25.02.2016                              Miete  living\n",
      "65   01.04.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "76   22.03.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "83   15.03.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "84   15.03.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "94   03.03.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "101  01.03.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "117  22.02.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "118  19.02.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "123  15.02.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "124  15.02.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "127  09.02.2016                   Euro-Überweisung  living\n",
      "128  08.02.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "142  01.02.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "157  20.01.2016  Lastschrift (Einzugsermächtigung)  living\n",
      "164  13.01.2016                   Euro-Überweisung  living\n",
      "171  28.06.2016                              Miete  living\n",
      "182  27.05.2016                              Miete  living\n",
      "189  27.04.2016                              Miete  living\n",
      "195  29.03.2016                              Miete  living\n",
      "201  25.02.2016                              Miete  living\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['label'] == 'living'][['Buchungstag', 'Buchungstext', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Auftragskonto\" and \"Waehrung\" do not carry any additional information, because for \"Waehrung\" there is only one value - EUR, and for \"Auftragskonto\" there are only two values or it is absent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for Waehrung:\n",
      "EUR\n"
     ]
    }
   ],
   "source": [
    "print('Unique values for Waehrung:')\n",
    "for l in df[\"Waehrung\"].unique():\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for Auftragskonto:\n",
      "89990201.0\n",
      "89990210.0\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print('Unique values for Auftragskonto:')\n",
    "for l in df[\"Auftragskonto\"].unique():\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              label  mean    min   max\n",
      "0            income  2021   1793  2986\n",
      "1            living  -286   -670   276\n",
      "2           private  -161  -1000   100\n",
      "3  standardOfLiving  -157  -5000    -5\n",
      "4           leisure   -54   -535     5\n",
      "5           finance  -358  -4000   200\n"
     ]
    }
   ],
   "source": [
    "df[\"Betrag\"] = df[\"Betrag\"].apply(str).str.replace(\",\", \".\")\n",
    "df[\"Betrag\"] = df[\"Betrag\"].astype(float)\n",
    "df_betrag = pd.DataFrame(columns=['label', 'mean', 'min', 'max'])\n",
    "\n",
    "for l in df[\"label\"].unique():\n",
    "    df_betrag = df_betrag.append(\n",
    "        {'label': l,\n",
    "        'mean': round(df.loc[df[\"label\"] == l, 'Betrag'].mean()),\n",
    "        'min': round(df.loc[df[\"label\"] == l, 'Betrag'].min()),\n",
    "        'max': round(df.loc[df[\"label\"] == l, 'Betrag'].max())}, ignore_index=True\n",
    "    )\n",
    "\n",
    "print(df_betrag)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Betrag\" is also a bad feature because any transaction can has any amount of money. Only \"income\" is always positive, but even in this case \"Buchungstext\" is directly related to \"Betrag\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Betrag   Buchungstext   label\n",
      "0    2000.00  Lohn / Gehalt  income\n",
      "10   2000.00  Lohn / Gehalt  income\n",
      "21   2000.00  Lohn / Gehalt  income\n",
      "28   2000.00  Lohn / Gehalt  income\n",
      "34   2000.00  Lohn / Gehalt  income\n",
      "40   2000.00  Lohn / Gehalt  income\n",
      "46   2000.00  Lohn / Gehalt  income\n",
      "48   1792.73   Gehalt/Rente  income\n",
      "70   1792.73   Gehalt/Rente  income\n",
      "108  2986.24   Gehalt/Rente  income\n",
      "147  1792.73   Gehalt/Rente  income\n",
      "170  2000.00  Lohn / Gehalt  income\n",
      "181  2000.00  Lohn / Gehalt  income\n",
      "188  2000.00  Lohn / Gehalt  income\n",
      "194  2000.00  Lohn / Gehalt  income\n",
      "200  2000.00  Lohn / Gehalt  income\n",
      "206  2000.00  Lohn / Gehalt  income\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['label'] == 'income'][['Betrag', 'Buchungstext', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\"Verwendungszweck\" - In general, this field can be anything at all, but if you look closely at the table, usually this field contains the same information from other fields, or it is indirectly described using other fields. Having so small database for training, additional transformations or extraction of keywords for clasification will not bring additional advantage, but on the contrary will increase overfitting in relation to new transaction.\n",
    "<p>\n",
    "<p>\"Beguenstigter/Zahlungspflichtiger\" are also not important because \"Kontonummer\" and \"BLZ\" are the bank details of those who pay.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buchungstext\n",
      "Kontonummer\n",
      "BLZ\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"Auftragskonto\", \"Buchungstag\", \"Verwendungszweck\", \"Beguenstigter/Zahlungspflichtiger\", \"Valutadatum\", \"Betrag\", \"Waehrung\"], axis=1, inplace=True)\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For training my classifier i have use only three features: Buchungstext, Kontonummer, BLZ. Categorical variable of features were converted into dummy/indicator variables using pandas.get_dummies.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.get_dummies(df[df.columns[0:-1]]).values\n",
    "classes = np.unique(df[df.columns[-1]])\n",
    "d = dict(zip(classes, np.arange(classes.shape[0])))\n",
    "labels = df[df.columns[-1]].map(d, na_action='ignore').values\n",
    "\n",
    "labels = labels.reshape(-1,1)\n",
    "data = np.hstack((features, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows that there is a class imbalance in this dataset. Applying inappropriate evaluation metrics for model generated using imbalanced data can be dangerous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label               %\n",
      "leisure             31.100478\n",
      "standardOfLiving    22.488038\n",
      "finance             15.789474\n",
      "living              12.440191\n",
      "private             10.047847\n",
      "income               8.133971\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('label               %')\n",
    "print(df['label'].value_counts()/len(df['label'])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, other alternative evaluation metrics can be applied such as:\n",
    "<ol>\n",
    "  <li>F1 score: harmonic mean of precision and recall.</li>\n",
    "  <li>MCC: correlation coefficient between the observed and predicted binary classifications.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1  = 0.913\n",
      "mcc = 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "n = 100\n",
    "f1 = 0\n",
    "mcc = 0\n",
    "for i in range(n):\n",
    "    gnb = GaussianNB()\n",
    "    train, test = train_test_split(data, test_size=0.1)\n",
    "    gnb = gnb.fit(train[:, :-1], train[:, -1])\n",
    "\n",
    "    y_pred = gnb.predict(test[:, :-1])\n",
    "\n",
    "    f1 += f1_score(test[:, -1], y_pred, average='micro')\n",
    "    mcc += matthews_corrcoef(test[:, -1], y_pred)\n",
    "\n",
    "print(\"f1  =\", round(f1/n, 3))\n",
    "print(\"mcc =\", round(mcc/n, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a hundred times the classifier's training with a random splitting of data on the train and test, the average results obtained are quite high. To improve the scores of the classifier, it is necessary to use more data, then perhaps the discarded features can significantly affect the result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
